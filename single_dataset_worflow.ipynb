{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:28:05.249129Z",
     "start_time": "2024-05-15T12:28:05.232568Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e22950-9e8a-4ee9-b386-984183be60c8",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4486e1b-7ed8-4dab-948b-497d66ca94cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:28:07.819701Z",
     "start_time": "2024-05-15T12:28:05.250472Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d352e9f-505d-4fd2-82f6-12b19e12c90f",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.python.domain.domain_services import is_valid_dataset\n",
    "from src.python.service.utils import (\n",
    "    test_dataset_binary_numeric,\n",
    "    convert_to_binary_dataset,\n",
    ")\n",
    "from src.python.domain.domain_services import get_nn_model, get_nn_inference\n",
    "from src.python.domain.domain_services import classification_diagnostics\n",
    "from src.python.domain.domain_services import create_bootstrap_dataset\n",
    "from src.python.domain.Algorithms import TemperatureScaler\n",
    "from src.python.domain.domain_services import white_list_uci_ids\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "dataset_meta_ls = [\n",
    "    x\n",
    "    for x in json.load(open(\"uci_datasets_meta1.json\", \"rb\"))\n",
    "    if x[\"uci_id\"] in white_list_uci_ids\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2774495b-ee27-4bdb-91f7-410a247adbb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf_dict = json.loads(dbutils.widgets.get(\"config\"))\n",
    "print(conf_dict)\n",
    "for key, value in conf_dict.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d668c323-4d3a-4830-9bdd-af577ed9e79d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_results(input_tuple) -> dict:\n",
    "    dataset_meta, model_params = input_tuple[0], input_tuple[1]\n",
    "    if is_valid_dataset(dataset_meta):\n",
    "        print(f\"Processing dataset: {dataset_meta['name']}\")\n",
    "        dataset = fetch_ucirepo(id=dataset_meta[\"uci_id\"])\n",
    "        X, feat_names, y = convert_to_binary_dataset(\n",
    "            dataset.data.features, dataset.data.targets.iloc[:, 0]\n",
    "        )\n",
    "        test_dataset_binary_numeric(X, y)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=42\n",
    "        )\n",
    "\n",
    "        model, scaler = get_nn_model(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            model_params[\"base_nn_hidden_size\"],\n",
    "            model_params[\"base_nn_hidden_layers\"],\n",
    "            model_params[\"base_nn_n_epochs\"],\n",
    "        )\n",
    "        probs = get_nn_inference(model, X_val, y_val, scaler)\n",
    "\n",
    "        calib_df = pd.concat(\n",
    "            [\n",
    "                X_val.reset_index(drop=True),\n",
    "                pd.DataFrame(probs, columns=[\"predicted_prob\"]),\n",
    "                pd.DataFrame(y_val.values, columns=[\"label\"]),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        calib_train_df, calib_val_df = train_test_split(\n",
    "            calib_df, test_size=0.6, random_state=42\n",
    "        )\n",
    "\n",
    "        calibration_models = []\n",
    "\n",
    "        # # forecal plus based calibration\n",
    "        # bootstrap_df = create_bootstrap_dataset(\n",
    "        #     calib_train_df,\n",
    "        #     model_params[\"calibration_forecal_n_bins\"],\n",
    "        #     model_params[\"calibration_forecal_n_samples\"],\n",
    "        #     random_state=42,\n",
    "        # )\n",
    "\n",
    "        # cols = list(\n",
    "        #     bootstrap_df.columns\n",
    "        # )  # make the predicted probability as the first column for monotonic constraint\n",
    "        # cols.insert(0, cols.pop(cols.index(\"predicted_prob_mean\")))\n",
    "        # bootstrap_df = bootstrap_df.loc[:, cols]\n",
    "\n",
    "        # X_train = bootstrap_df.drop(columns=[\"label_mean\"])\n",
    "        # y_train = bootstrap_df[\"label_mean\"]\n",
    "\n",
    "        # fc = RandomForestRegressor(\n",
    "        #     n_estimators=100,\n",
    "        #     random_state=42,\n",
    "        #     monotonic_cst=([1] + [0] * (X_train.shape[1] - 1)),\n",
    "        # )\n",
    "        # fc.fit(X_train, y_train)\n",
    "        # calibration_models.append(\n",
    "        #     {\"model\": fc, \"name\": \"forecal-plus\", \"features\": X_train.columns.to_list()}\n",
    "        # )\n",
    "\n",
    "        # forecal based calibration\n",
    "\n",
    "        bootstrap_df = create_bootstrap_dataset(\n",
    "            calib_train_df,\n",
    "            model_params[\"calibration_forecal_n_bins\"],\n",
    "            model_params[\"calibration_forecal_n_samples\"],\n",
    "            random_state=42,\n",
    "        )\n",
    "        cols = list(\n",
    "            bootstrap_df.columns\n",
    "        )  # make the predicted probability as the first column for monotonic constraint\n",
    "        cols.insert(0, cols.pop(cols.index(\"predicted_prob_mean\")))\n",
    "        bootstrap_df = bootstrap_df.loc[:, cols]\n",
    "\n",
    "        X_train = bootstrap_df[[\"predicted_prob_mean\"]]\n",
    "        y_train = bootstrap_df[\"label_mean\"]\n",
    "\n",
    "        fc = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            monotonic_cst=([1] + [0] * (X_train.shape[1] - 1)),\n",
    "        )\n",
    "        fc.fit(X_train, y_train)\n",
    "        print(fc)\n",
    "        calibration_models.append(\n",
    "            {\"model\": fc, \"name\": \"forecal\", \"features\": [\"predicted_prob_mean\"]}\n",
    "        )\n",
    "\n",
    "        # isotonic regression based calibration\n",
    "        X_train = calib_train_df[\"predicted_prob\"].values.reshape(-1, 1)\n",
    "        y_train = calib_train_df[\"label\"].values\n",
    "        ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        ir.fit(X_train.flatten(), y_train)\n",
    "        calibration_models.append(\n",
    "            {\"model\": ir, \"name\": \"isotonic\", \"features\": [\"predicted_prob\"]}\n",
    "        )\n",
    "\n",
    "        # logistic regression based calibration called platt scaling\n",
    "        X_train = calib_train_df[\"predicted_prob\"].values.reshape(-1, 1)\n",
    "        y_train = calib_train_df[\"label\"].values\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        calibration_models.append(\n",
    "            {\"model\": lr, \"name\": \"platt\", \"features\": [\"predicted_prob\"]}\n",
    "        )\n",
    "\n",
    "        # # temperature scaling\n",
    "        X_train = calib_train_df[\"predicted_prob\"].values.reshape(-1, 1)\n",
    "        y_train = calib_train_df[\"label\"].values\n",
    "        temp_scaler = TemperatureScaler()\n",
    "        temp_scaler.fit(X_train, y_train)\n",
    "        calibration_models.append(\n",
    "            {\"model\": temp_scaler, \"name\": \"tempscaler\", \"features\": [\"predicted_prob\"]}\n",
    "        )\n",
    "\n",
    "        X_val = calib_val_df.drop(columns=[\"label\"])\n",
    "        y_val = calib_val_df[\"label\"].values\n",
    "\n",
    "        result_ls = []\n",
    "        for models in [\n",
    "            {\"model\": None, \"name\": \"baseline\", \"features\": None}\n",
    "        ] + calibration_models:\n",
    "            if models[\"name\"] == \"baseline\":\n",
    "                calibrated_probs = X_val[\"predicted_prob\"]\n",
    "            elif models[\"name\"].startswith(\"fore\"):\n",
    "                X = X_val.rename(columns=lambda x: x + \"_mean\")[models[\"features\"]]\n",
    "                calibrated_probs = models[\"model\"].predict(X)\n",
    "            elif models[\"name\"] == \"platt\":\n",
    "                calibrated_probs = models[\"model\"].predict_proba(\n",
    "                    X_val[models[\"features\"]]\n",
    "                )[:, 1]\n",
    "            elif models[\"name\"] == \"isotonic\":\n",
    "                calibrated_probs = models[\"model\"].predict(X_val[models[\"features\"]])\n",
    "            elif models[\"name\"] == \"tempscaler\":\n",
    "                calibrated_probs = models[\"model\"].predict(X_val[\"predicted_prob\"])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown calibration model: {models['name']}\")\n",
    "\n",
    "            plt, ece, auc = classification_diagnostics(\n",
    "                y_val, calibrated_probs, n_bins=10\n",
    "            )\n",
    "            result_ls.append({\"name\": models[\"name\"], \"ece\": ece, \"auc\": auc})\n",
    "            print(\n",
    "                f\"Expected Calibration Error (ECE) for {models['name']}: {ece:.4f} AUC: {auc:.4f}\"\n",
    "            )\n",
    "\n",
    "        res = {\n",
    "            \"dataset\": dataset_meta[\"name\"],\n",
    "            \"results\": result_ls,\n",
    "            \"uri_id\": dataset_meta[\"uci_id\"],\n",
    "            \"dataset_meta\": dataset_meta,\n",
    "            \"model_params\": model_params,\n",
    "        }\n",
    "        return res\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7ac500-9270-4130-8d21-e453eb081b6c",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "source": [
    "## NN Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:51:07.717770Z",
     "start_time": "2024-05-15T12:28:07.865269Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbfad9a-bd78-4440-a3d9-d92fb9f8bf94",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_list = list(product(dataset_meta_ls, model_params))\n",
    "total_ = len(arg_list)\n",
    "print(f\"Total number of runs: {total_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "266cbd51-c6f7-4cb4-bfa3-5836345e16ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with multiprocessing.pool.ThreadPool(total_) as pool:\n",
    "    with tqdm(total=total_) as pbar:\n",
    "        result_list = []\n",
    "        for result in pool.imap_unordered(get_results, arg_list):\n",
    "            result_list.append(result)\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:51:07.723362Z",
     "start_time": "2024-05-16T01:51:07.722593Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c7503b1-6166-4d94-be72-7455c1d87dcd",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(run_params[\"run_output\"], \"w\") as f:\n",
    "    json.dump({\"meta\": run_params, \"data\": result_list}, f)\n",
    "    print(f\"Results saved at: {run_params['run_output']}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "single_dataset_worflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
